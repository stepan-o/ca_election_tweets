{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "This notebook is the first step in our processing pipeline. It takes raw JSON files (~150mb in size), picks\n",
    "out hand selected fields, and saves them to smaller CSV files.\n",
    "\n",
    "### Note: You might have to change base directory, to get this to run. \n",
    "\n",
    "Script assumes that data folder is ../.. levels up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "baseDir = \"../../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def getframes(argTuple):   \n",
    "    index = argTuple[0]    \n",
    "    fileName = argTuple[1]\n",
    "\n",
    "    #Lets read in the tweets, and convert them to a DataFrame\n",
    "    topLevelFields = [\"id\",\"created_at\", \"text\",\"quote_count\",\"reply_count\",\"retweet_count\",\n",
    "                      \"favorite_count\",\"user_id\",\"user_screen_name\"]\n",
    "\n",
    "    userFields = [\"id\", \"created_at\", \"name\", \"screen_name\", \"verified\", \"followers_count\", \n",
    "                  \"friends_count\", \"favourites_count\", \"statuses_count\", \n",
    "                 \"profile_background_color\",\"profile_text_color\"]\n",
    "\n",
    "    userCheckDict = {\"test\": 1}\n",
    "\n",
    "    #make an empty DF.\n",
    "    tweetDF = pd.DataFrame(columns=topLevelFields + [\"hashtag_list\"])\n",
    "    userDF = pd.DataFrame(columns=userFields)  #list(map(lambda x: \"user_\" + x , userFields)))\n",
    "\n",
    "    def parsetweet(jsonObj):\n",
    "        retList = []\n",
    "        for label in topLevelFields[:len(topLevelFields) - 2]: \n",
    "            retList.append(jsonObj[label])\n",
    "\n",
    "        hashTagString = \"\"\n",
    "        if jsonObj[\"entities\"][\"hashtags\"]:\n",
    "            for item in jsonObj[\"entities\"][\"hashtags\"]:\n",
    "                hashTagString = hashTagString + \",\" + item[\"text\"]\n",
    "            hashTagString = hashTagString[1:]\n",
    "            \n",
    "        #Finally, we need to add foreign keys to the user table.\n",
    "        retList.append(jsonObj[\"user\"][\"id\"])\n",
    "        retList.append(jsonObj[\"user\"][\"screen_name\"])\n",
    "        \n",
    "        retList.append(hashTagString)\n",
    "        return retList       \n",
    "\n",
    "    def parseuser(jsonObj):\n",
    "        #first, extract id from jsonObj for user. Is it in our table of users?\n",
    "        #To check (quickly) for a users presence, we need a hash table.\n",
    "        #In python, dictionaries serve the same purpose\n",
    "        retList = []\n",
    "        if jsonObj[\"user\"][\"id\"] not in userCheckDict:\n",
    "            userCheckDict[jsonObj[\"user\"][\"id\"]] = 1\n",
    "            for label in userFields:\n",
    "                retList.append(jsonObj[\"user\"][label])\n",
    "\n",
    "        return retList\n",
    "        \n",
    "    with open(fileName, \"r\") as tweets_file:\n",
    "        for i,line in enumerate(tweets_file):\n",
    "            try:\n",
    "                tweet = json.loads(line)\n",
    "                tweetDF.loc[tweetDF.shape[0]] = parsetweet(tweet)\n",
    "                retList = parseuser(tweet)\n",
    "                if retList: #Not empty: \n",
    "                    userDF.loc[userDF.shape[0]] = retList\n",
    "            except ValueError as e:\n",
    "                print('Handling run-time error:', e)            \n",
    "        tweets_file.close()\n",
    "    tweetDF.to_csv(baseDir + \"1.stage1/tweets/\" + \"tweets\" + str(index) + \".csv\")\n",
    "    userDF.to_csv(baseDir + \"1.stage1/users/\" + \"users\" + str(index) + \".csv\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code:\n",
    "\n",
    "Warning: **Do not** use all 16 cores with Ray; you need 1 or more cores to run your GUI and terminals. I have set it to 12 to be safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-23 21:05:34,707\tINFO resource_spec.py:205 -- Starting Ray with 7.42 GiB memory available for workers and up to 3.73 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=17634)\u001b[0m Handling run-time error: Expecting value: line 1 column 1 (char 0)\n",
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "#Only call once! \n",
    "\n",
    "ray.init(num_cpus=12) #One File per CPU. Don't exceed 12 (avoid console lockup).\n",
    "startDir = \"../../data/1.stage0/\"\n",
    "enumList = list(enumerate(glob.glob(startDir+\"*\")))\n",
    "\n",
    "idLists = [getframes.remote(name) for name in enumList]\n",
    "\n",
    "print(ray.get(idLists))\n",
    "\n",
    "ray.shutdown() #Always shutdown; you will have old processes lying around if you dont.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use if script crashes. Ray doesn't clean up after itself.\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
