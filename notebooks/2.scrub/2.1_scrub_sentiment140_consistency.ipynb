{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2019 Canadian Election tweets\n",
    "# OSEMN Step 2: Scrub\n",
    "# Cleanup of Sentiment 140 dataset\n",
    "# Correcting records for consistency\n",
    "\n",
    "This notebook describes part of Step 2: Scrub of OSEMN methodology. It covers cleanup of Sentiment 140.\n",
    "\n",
    "Cleanup plan (stage 1, correction for consistency):\n",
    "\n",
    "1. Parse dates\n",
    "2. Replace HTML character codes\n",
    "3. Replace unicode characters\n",
    "4. Remove erratic text\n",
    "5. Remove links from tweets\n",
    "6. Remove tweets with erratic text length\n",
    "7. Parse hashtags from tweets\n",
    "8. Parse user handles from tweets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import dependencies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from time import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['sentiment140_train_cleaned.csv',\n 'testdata.manual.2009.06.14.csv',\n 'training.1600000.processed.noemoticon.csv']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "data_dir = '../../data/sentiment140/'\n",
    "os.listdir(data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Sentiment 140 dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "----- DataFrame loaded\nin 3.98 seconds\nwith 1,600,000 rows\nand 6 columns\n-- Column names:\n Index(['sentiment', 'ids', 'date', 'query', 'user', 'text'], dtype='object')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "t = time()\n",
    "train_df = pd.read_csv(data_dir + 'training.1600000.processed.noemoticon.csv', \n",
    "                       encoding=\"ISO-8859-1\", header=None)\n",
    "elapsed = time() - t\n",
    "train_df.columns = ['sentiment', 'ids', 'date', 'query', 'user', 'text']\n",
    "print(\"----- DataFrame loaded\"\n",
    "      \"\\nin {0:.2f} seconds\".format(elapsed) +\n",
    "      \"\\nwith {0:,} rows\\nand {1:,} columns\"\n",
    "      .format(train_df.shape[0], train_df.shape[1]) +\n",
    "      \"\\n-- Column names:\\n\", train_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parse dates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/stepan/anaconda3/envs/twitter/lib/python3.7/site-packages/dateutil/parser/_parser.py:1206: UnknownTimezoneWarning: tzname PDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n  category=UnknownTimezoneWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Date was parsed. Took 248.07 seconds (4.13 minutes)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "t = time()\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "elapsed = time() - t\n",
    "print(\"Date was parsed. Took {0:,.2f} seconds ({1:,.2f} minutes)\".format(elapsed, elapsed / 60))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Replace HTML character codes\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Replace '<3' with 'love':"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Done!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train_df['text'] = train_df['text'].str.replace(\"&lt;3\", 'love')\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HTML character codes:\n",
    "\n",
    "The following HTML character codes will be replaced with symbols:\n",
    "* &quot;\n",
    "* &amp;\n",
    "* &lt;\n",
    "* &gt;"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "HTML character codes were replaced with their ASCII equivalent.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# replacing HTML character codes with their ASCII equivalents\n",
    "train_df['text'] = train_df['text'].str.replace(\"&quot;\", '\"')\n",
    "train_df['text'] = train_df['text'].str.replace(\"&amp;\", '&')\n",
    "train_df['text'] = train_df['text'].str.replace(\"&lt;\", '<')\n",
    "train_df['text'] = train_df['text'].str.replace(\"&gt;\", '>')\n",
    "print(\"HTML character codes were replaced with their ASCII equivalent.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Replace unicode characters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Unicode characters were replaced with their ASCII equivalent.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# replacing unicode character codes with their ASCII equivalents\n",
    "train_df['text'] = train_df['text'].str.replace(\"ï¿½\", \"'\")\n",
    "print(\"Unicode characters were replaced with their ASCII equivalent.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove erratic text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "244842    @michichan ã?ã??ã?ã?§ã?ã?ã ã?ã?¿ã?¾ã?ã...\n245862    Tháº¿ mÃ  chÆ°a báº¯t ÄÆ°á»£c con cÃ¡ nÃ o, t...\n245941    @13th ÑÑÐ¾ Ñ?Ð¾Ð²Ñ?ÐµÐ¼ Ð¿Ð»Ð¾Ñ\nÐ¾?  Ð° blue...\n245949    má»t wa', thÃ´i mai lÃ m tiáº¿p, cÃ²n 3 chá»¯...\n246160    hic, mÃ£i má»i cÃ i xong cÃ¡i giáº£i thuáº­t ...\nName: text, dtype: object"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "mask1 = train_df['text'].str.contains('¿')\n",
    "train_df.loc[mask1, 'text'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1,599,445 records remaining in the DataFrame.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train_df = train_df[~mask1]\n",
    "print(\"{0:,} records remaining in the DataFrame.\".format(len(train_df)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove links"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "70,135 records contain 'http' in 'text'.\n\n@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n@MissXu sorry! bed time came here (GMT+1)   http://is.gd/fNge\nBroadband plan 'a massive broken promise' http://tinyurl.com/dcuc33 via www.diigo.com/~tautao Still waiting for broadband we are \nWhy won't you show my location?!   http://twitpic.com/2y2es\nStrider is a sick little puppy  http://apps.facebook.com/dogbook/profile/view/5248435\n Body Of Missing Northern Calif. Girl Found: Police have found the remains of a missing Northern California girl .. http://tr.im/imji\nEmily will be glad when Mommy is done training at her new job. She misses her.  http://apps.facebook.com/dogbook/profile/view/6176014\nCrazy wind today = no birding  http://ff.im/1XTTi\nCheck out my mug  http://www.erika-obscura.blogspot.com\nhttp://twitpic.com/2y2wr - according to my bro, our new puppy had a poo fight and was covered in poop  (picture stolen from him)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "mask = train_df['text'].str.contains('http')\n",
    "print(\"{0:,} records contain 'http' in 'text'.\\n\".format(len(train_df[mask])))\n",
    "for i in np.arange(10): print(train_df.loc[mask, 'text'].iloc[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Links have been removed from the column 'text' of the DataFrame! Took 1.97 seconds (0.03 minutes)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "t = time()\n",
    "train_df['text'] = train_df['text'].apply(lambda text: re.sub(r'http\\S+', '', text))\n",
    "elapsed = time() - t\n",
    "print(\"Links have been removed from the column 'text' of the DataFrame! Took {0:,.2f} seconds ({1:,.2f} minutes)\"\n",
    "      .format(elapsed, elapsed / 60))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "17 records contain 'http' in 'text'.\n\nmight have to make some changes to ruby twitter .. it doesn't include headers coming back ..so no API count without a serperate http call \n\"The Gmail gadget does not support the \"Always use  grr doofes igoogle  will aber kein http nutzen........\nsofranel.eu updated : new url management. I hope it will improve Google referencing...  But again some little problems with CSS  http ...\n@PatchouliW 1&1 internet hosting sucks cos they only allow you to carry light weight apps and only internal apps so no sl http requests \nWtf is http streaming??? I still want flash 10 for iPhone  ITS SUNNY WOOOOO..... I need skittles -.- taste the rainbow!!!\n@holytshirt gutted, they block http flickr at work \nCan't get VLC http interface connected ;( now i've got to fysically move to my computer for play/pause  anyone tips? S not firewall afaik\n(@JenniferEllenM)Went to see Bob Dylan last night, was amazin'  Going to work soon. I was put on till 13 for my first ever shift! http ...\n@asolomon15 yes, but to do the same thing with cURL it's like 4 times as long. I was thinking cURL was the only way to get http headers \n@jonasdelosreyes Lakers back to the finals after beating Nuggets 119-92! Now, who do you think they'll face, Magic or Cavs?  #nba http ...\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# subset all records that contain 'http' in the tweet 'text'\n",
    "mask = train_df['text'].str.contains('http')\n",
    "print(\"{0:,} records contain 'http' in 'text'.\\n\".format(len(train_df[mask])))\n",
    "\n",
    "# if more than 10 records returned, print 10\n",
    "len_to_print = 0\n",
    "if len(train_df[mask]) > 10: len_to_print = 10\n",
    "else: lin_to_print = len(train_df[mask])\n",
    "\n",
    "for i in np.arange(len_to_print): print(train_df.loc[mask, 'text'].iloc[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove tweets with text > 150 characters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Column 'text_len' was added to the DataFrame. Took 0.40 seconds (0.01 minutes)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "t = time()\n",
    "# add a new column with length of strings in 'text' to the DataFrame with generic tweets\n",
    "train_df['text_len'] = train_df['text'].str.len()\n",
    "elapsed = time() - t\n",
    "print(\"Column 'text_len' was added to the DataFrame. Took {0:,.2f} seconds ({1:,.2f} minutes)\"\n",
    "      .format(elapsed, elapsed / 60))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Tweets longer than 150 characters\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "                   user                                               text  \\\n245571       candiceccl  ä»²æä¸èª²adverse possessionï¼?ä½ä¹å?çc...   \n248243         moriator  @anhhung cÃ i moto4lin rá»i anh  XÃ i ÄÆ°á»£...   \n258460             B6ah  @CrEaTiVe_B Ø§Ø®ØªØ¨Ø§Ø±Ù .. final freshman l...   \n258511             B6ah  @CrEaTiVe_B Ø¹ÙØ¯Ù ÙÙÙØ² 8Ø§ÙØµØ¨Ø­ Ù Ø...   \n265700           tukata  @pammanista à¸¨à¸²à¸¥à¸à¸£à¸°à¸ à¸¹à¸¡à¸´ na ...   \n...                 ...                                                ...   \n1583033         im_nlfb  @traquannet Chá»? tÃ­ nhÃ©, mÃ¬nh cÃ i tweetde...   \n1583052          5ummer  @manubkk @bkkdude Tks for sharing ka.  But if ...   \n1586631  LaMiaVitaBella  @RawkerChick Currently obsessed with...WATERME...   \n1587593         kuturak  Ð?Ð°Ñ?ÑÑÐ¾ÐµÐ½Ð¸ÐµÑÐ¾ Ð¼Ð¸ Ð´Ð½ÐµÑ? Ðµ Ð² Ð...   \n1595705        gchandra  @ravidreams orutharuku onnu pudikathunu therin...   \n\n         text_len  \n245571        166  \n248243        156  \n258460        181  \n258511        154  \n265700        151  \n...           ...  \n1583033       170  \n1583052       151  \n1586631       151  \n1587593       167  \n1595705       186  \n\n[139 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>text</th>\n      <th>text_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>245571</td>\n      <td>candiceccl</td>\n      <td>ä»²æä¸èª²adverse possessionï¼?ä½ä¹å?çc...</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <td>248243</td>\n      <td>moriator</td>\n      <td>@anhhung cÃ i moto4lin rá»i anh  XÃ i ÄÆ°á»£...</td>\n      <td>156</td>\n    </tr>\n    <tr>\n      <td>258460</td>\n      <td>B6ah</td>\n      <td>@CrEaTiVe_B Ø§Ø®ØªØ¨Ø§Ø±Ù .. final freshman l...</td>\n      <td>181</td>\n    </tr>\n    <tr>\n      <td>258511</td>\n      <td>B6ah</td>\n      <td>@CrEaTiVe_B Ø¹ÙØ¯Ù ÙÙÙØ² 8Ø§ÙØµØ¨Ø­ Ù Ø...</td>\n      <td>154</td>\n    </tr>\n    <tr>\n      <td>265700</td>\n      <td>tukata</td>\n      <td>@pammanista à¸¨à¸²à¸¥à¸à¸£à¸°à¸ à¸¹à¸¡à¸´ na ...</td>\n      <td>151</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>1583033</td>\n      <td>im_nlfb</td>\n      <td>@traquannet Chá»? tÃ­ nhÃ©, mÃ¬nh cÃ i tweetde...</td>\n      <td>170</td>\n    </tr>\n    <tr>\n      <td>1583052</td>\n      <td>5ummer</td>\n      <td>@manubkk @bkkdude Tks for sharing ka.  But if ...</td>\n      <td>151</td>\n    </tr>\n    <tr>\n      <td>1586631</td>\n      <td>LaMiaVitaBella</td>\n      <td>@RawkerChick Currently obsessed with...WATERME...</td>\n      <td>151</td>\n    </tr>\n    <tr>\n      <td>1587593</td>\n      <td>kuturak</td>\n      <td>Ð?Ð°Ñ?ÑÑÐ¾ÐµÐ½Ð¸ÐµÑÐ¾ Ð¼Ð¸ Ð´Ð½ÐµÑ? Ðµ Ð² Ð...</td>\n      <td>167</td>\n    </tr>\n    <tr>\n      <td>1595705</td>\n      <td>gchandra</td>\n      <td>@ravidreams orutharuku onnu pudikathunu therin...</td>\n      <td>186</td>\n    </tr>\n  </tbody>\n</table>\n<p>139 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "max_len = 150\n",
    "mask1 = train_df['text_len'] > max_len\n",
    "print(\"Tweets longer than {0} characters\".format(max_len))\n",
    "train_df.loc[mask1, ['user', 'text', 'text_len']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b7eb5cf90>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "train_df.loc[mask1, 'text_len'].hist(bins=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1,599,306 records remaining in the DataFrame.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train_df = train_df[~mask1].drop('text_len', axis=1)\n",
    "print(\"{0:,} records remaining in the DataFrame.\".format(len(train_df)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parse hashtags from tweets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Hashtags have been extracted into a new column 'hashtags' of the DataFrame!Took 1.76 seconds (0.03 minutes)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "t = time()\n",
    "train_df['hashtags'] = train_df['text'].apply(lambda text: \" \".join(re.findall(r'#\\w+', text)))\n",
    "elapsed = time() - t\n",
    "print(\"Hashtags have been extracted into a new column 'hashtags' of the DataFrame!\"\n",
    "      \"Took {0:,.2f} seconds ({1:,.2f} minutes)\".format(elapsed, elapsed / 60))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parse user handles from tweets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "User @ handles have been extracted into a new column 'handles' of the DataFrame!Took 2.04 seconds (0.03 minutes)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "t = time()\n",
    "train_df['handles'] = train_df['text'].apply(lambda text: \" \".join(re.findall(r'@\\w+', text)))\n",
    "elapsed = time() - t\n",
    "print(\"User @ handles have been extracted into a new column 'handles' of the DataFrame!\"\n",
    "      \"Took {0:,.2f} seconds ({1:,.2f} minutes)\".format(elapsed, elapsed / 60))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save results to a .csv file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "DataFrame saved to file\n../../data/sentiment140/sentiment140_train_cleaned.csv\ntook 12.42 seconds (0.21 minutes)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "save_path = data_dir + 'sentiment140_train_cleaned.csv'\n",
    "t = time()\n",
    "train_df.to_csv(save_path, index=False)\n",
    "elapsed = time() - t\n",
    "print(\"DataFrame saved to file\\n{0}\\ntook {1:,.2f} seconds ({2:,.2f} minutes)\"\n",
    "      .format(save_path, elapsed, elapsed / 60))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}