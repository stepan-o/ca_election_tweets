{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 Canadian Election tweets\n",
    "# OSEMN Step 2: Scrub\n",
    "# Cleanup of Sentiment 140 dataset\n",
    "# Correcting records for consistency\n",
    "\n",
    "This notebook describes part of Step 2: Scrub of OSEMN methodology. It covers cleanup of Sentiment 140.\n",
    "\n",
    "Cleanup plan (stage 1, correction for consistency):\n",
    "\n",
    "1. Parse dates\n",
    "2. Replace HTML character codes\n",
    "3. Replace unicode characters\n",
    "4. Remove erratic text\n",
    "5. Remove links from tweets\n",
    "6. Remove tweets with erratic text length\n",
    "7. Parse hashtags from tweets\n",
    "8. Parse user handles from tweets\n",
    "9. Apply text preprocessor\n",
    "10. Remove non-English unicode characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../src')\n",
    "from nlp_utils import preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testdata.manual.2009.06.14.csv',\n",
       " 'training.1600000.processed.noemoticon.csv',\n",
       " 'sentiment140_train_nodup.csv',\n",
       " 'sentiment140_train_cleaned.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../../data/sentiment140/'\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Sentiment 140 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- DataFrame loaded\n",
      "in 4.67 seconds\n",
      "with 1,600,000 rows\n",
      "and 6 columns\n",
      "-- Column names:\n",
      " Index(['sentiment', 'ids', 'date', 'query', 'user', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "train_df = pd.read_csv(data_dir + 'training.1600000.processed.noemoticon.csv', \n",
    "                       encoding=\"ISO-8859-1\", header=None)\n",
    "elapsed = time() - t\n",
    "train_df.columns = ['sentiment', 'ids', 'date', 'query', 'user', 'text']\n",
    "print(\"----- DataFrame loaded\"\n",
    "      \"\\nin {0:.2f} seconds\".format(elapsed) +\n",
    "      \"\\nwith {0:,} rows\\nand {1:,} columns\"\n",
    "      .format(train_df.shape[0], train_df.shape[1]) +\n",
    "      \"\\n-- Column names:\\n\", train_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Parse dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stepan/anaconda3/envs/twitter/lib/python3.7/site-packages/dateutil/parser/_parser.py:1206: UnknownTimezoneWarning: tzname PDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date was parsed. Took 367.43 seconds (6.12 minutes)\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "elapsed = time() - t\n",
    "print(\"Date was parsed. Took {0:,.2f} seconds ({1:,.2f} minutes)\".format(elapsed, elapsed / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Replace HTML character codes\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace '<3' with 'love':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_df['text'] = train_df['text'].str.replace(\"&lt;3\", 'love')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML character codes:\n",
    "\n",
    "The following HTML character codes will be replaced with symbols:\n",
    "* &quot;\n",
    "* &amp;\n",
    "* &lt;\n",
    "* &gt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML character codes were replaced with their ASCII equivalent.\n"
     ]
    }
   ],
   "source": [
    "# replacing HTML character codes with their ASCII equivalents\n",
    "train_df['text'] = train_df['text'].str.replace(\"&quot;\", '\"')\n",
    "train_df['text'] = train_df['text'].str.replace(\"&amp;\", '&')\n",
    "train_df['text'] = train_df['text'].str.replace(\"&lt;\", '<')\n",
    "train_df['text'] = train_df['text'].str.replace(\"&gt;\", '>')\n",
    "print(\"HTML character codes were replaced with their ASCII equivalent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Replace unicode characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unicode characters were replaced with their ASCII equivalent.\n"
     ]
    }
   ],
   "source": [
    "# replacing unicode character codes with their ASCII equivalents\n",
    "train_df['text'] = train_df['text'].str.replace(\"ï¿½\", \"'\")\n",
    "print(\"Unicode characters were replaced with their ASCII equivalent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Remove erratic text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244842    @michichan ã?ã??ã?ã?§ã?ã?ã ã?ã?¿ã?¾ã?ã...\n",
       "245862    Tháº¿ mÃ  chÆ°a báº¯t ÄÆ°á»£c con cÃ¡ nÃ o, t...\n",
       "245941    @13th ÑÑÐ¾ Ñ?Ð¾Ð²Ñ?ÐµÐ¼ Ð¿Ð»Ð¾Ñ\n",
       "Ð¾?  Ð° blue...\n",
       "245949    má»t wa', thÃ´i mai lÃ m tiáº¿p, cÃ²n 3 chá»¯...\n",
       "246160    hic, mÃ£i má»i cÃ i xong cÃ¡i giáº£i thuáº­t ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1 = train_df['text'].str.contains('¿')\n",
    "train_df.loc[mask1, 'text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,599,445 records remaining in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df[~mask1]\n",
    "print(\"{0:,} records remaining in the DataFrame.\".format(len(train_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70,135 records contain 'http' in 'text'.\n",
      "\n",
      "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
      "@MissXu sorry! bed time came here (GMT+1)   http://is.gd/fNge\n",
      "Broadband plan 'a massive broken promise' http://tinyurl.com/dcuc33 via www.diigo.com/~tautao Still waiting for broadband we are \n",
      "Why won't you show my location?!   http://twitpic.com/2y2es\n",
      "Strider is a sick little puppy  http://apps.facebook.com/dogbook/profile/view/5248435\n",
      " Body Of Missing Northern Calif. Girl Found: Police have found the remains of a missing Northern California girl .. http://tr.im/imji\n",
      "Emily will be glad when Mommy is done training at her new job. She misses her.  http://apps.facebook.com/dogbook/profile/view/6176014\n",
      "Crazy wind today = no birding  http://ff.im/1XTTi\n",
      "Check out my mug  http://www.erika-obscura.blogspot.com\n",
      "http://twitpic.com/2y2wr - according to my bro, our new puppy had a poo fight and was covered in poop  (picture stolen from him)\n"
     ]
    }
   ],
   "source": [
    "mask = train_df['text'].str.contains('http')\n",
    "print(\"{0:,} records contain 'http' in 'text'.\\n\".format(len(train_df[mask])))\n",
    "for i in np.arange(10): print(train_df.loc[mask, 'text'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links were removed from the column 'text' of the DataFrame! Took 3.31 seconds (0.06 minutes)\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "train_df['text'] = train_df['text'].apply(lambda text: re.sub(r'http\\S+', '', text))\n",
    "elapsed = time() - t\n",
    "print(\"Links were removed from the column 'text' of the DataFrame! Took {0:,.2f} seconds ({1:,.2f} minutes)\"\n",
    "      .format(elapsed, elapsed / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 records contain 'http' in 'text'.\n",
      "\n",
      "might have to make some changes to ruby twitter .. it doesn't include headers coming back ..so no API count without a serperate http call \n",
      "\"The Gmail gadget does not support the \"Always use  grr doofes igoogle  will aber kein http nutzen........\n",
      "sofranel.eu updated : new url management. I hope it will improve Google referencing...  But again some little problems with CSS  http ...\n",
      "@PatchouliW 1&1 internet hosting sucks cos they only allow you to carry light weight apps and only internal apps so no sl http requests \n",
      "Wtf is http streaming??? I still want flash 10 for iPhone  ITS SUNNY WOOOOO..... I need skittles -.- taste the rainbow!!!\n",
      "@holytshirt gutted, they block http flickr at work \n",
      "Can't get VLC http interface connected ;( now i've got to fysically move to my computer for play/pause  anyone tips? S not firewall afaik\n",
      "(@JenniferEllenM)Went to see Bob Dylan last night, was amazin'  Going to work soon. I was put on till 13 for my first ever shift! http ...\n",
      "@asolomon15 yes, but to do the same thing with cURL it's like 4 times as long. I was thinking cURL was the only way to get http headers \n",
      "@jonasdelosreyes Lakers back to the finals after beating Nuggets 119-92! Now, who do you think they'll face, Magic or Cavs?  #nba http ...\n"
     ]
    }
   ],
   "source": [
    "# subset all records that contain 'http' in the tweet 'text'\n",
    "mask = train_df['text'].str.contains('http')\n",
    "print(\"{0:,} records contain 'http' in 'text'.\\n\".format(len(train_df[mask])))\n",
    "\n",
    "# if more than 10 records returned, print 10\n",
    "len_to_print = 0\n",
    "if len(train_df[mask]) > 10: len_to_print = 10\n",
    "else: lin_to_print = len(train_df[mask])\n",
    "\n",
    "for i in np.arange(len_to_print): print(train_df.loc[mask, 'text'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Remove tweets with text > 150 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'text_len' was added to the DataFrame. Took 0.64 seconds (0.01 minutes)\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "# add a new column with length of strings in 'text' to the DataFrame with generic tweets\n",
    "train_df['text_len'] = train_df['text'].str.len()\n",
    "elapsed = time() - t\n",
    "print(\"Column 'text_len' was added to the DataFrame. Took {0:,.2f} seconds ({1:,.2f} minutes)\"\n",
    "      .format(elapsed, elapsed / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets longer than 150 characters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>245571</td>\n",
       "      <td>candiceccl</td>\n",
       "      <td>ä»²æä¸èª²adverse possessionï¼?ä½ä¹å?çc...</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248243</td>\n",
       "      <td>moriator</td>\n",
       "      <td>@anhhung cÃ i moto4lin rá»i anh  XÃ i ÄÆ°á»£...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258460</td>\n",
       "      <td>B6ah</td>\n",
       "      <td>@CrEaTiVe_B Ø§Ø®ØªØ¨Ø§Ø±Ù .. final freshman l...</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258511</td>\n",
       "      <td>B6ah</td>\n",
       "      <td>@CrEaTiVe_B Ø¹ÙØ¯Ù ÙÙÙØ² 8Ø§ÙØµØ¨Ø­ Ù Ø...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265700</td>\n",
       "      <td>tukata</td>\n",
       "      <td>@pammanista à¸¨à¸²à¸¥à¸à¸£à¸°à¸ à¸¹à¸¡à¸´ na ...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1583033</td>\n",
       "      <td>im_nlfb</td>\n",
       "      <td>@traquannet Chá»? tÃ­ nhÃ©, mÃ¬nh cÃ i tweetde...</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1583052</td>\n",
       "      <td>5ummer</td>\n",
       "      <td>@manubkk @bkkdude Tks for sharing ka.  But if ...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1586631</td>\n",
       "      <td>LaMiaVitaBella</td>\n",
       "      <td>@RawkerChick Currently obsessed with...WATERME...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1587593</td>\n",
       "      <td>kuturak</td>\n",
       "      <td>Ð?Ð°Ñ?ÑÑÐ¾ÐµÐ½Ð¸ÐµÑÐ¾ Ð¼Ð¸ Ð´Ð½ÐµÑ? Ðµ Ð² Ð...</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1595705</td>\n",
       "      <td>gchandra</td>\n",
       "      <td>@ravidreams orutharuku onnu pudikathunu therin...</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user                                               text  \\\n",
       "245571       candiceccl  ä»²æä¸èª²adverse possessionï¼?ä½ä¹å?çc...   \n",
       "248243         moriator  @anhhung cÃ i moto4lin rá»i anh  XÃ i ÄÆ°á»£...   \n",
       "258460             B6ah  @CrEaTiVe_B Ø§Ø®ØªØ¨Ø§Ø±Ù .. final freshman l...   \n",
       "258511             B6ah  @CrEaTiVe_B Ø¹ÙØ¯Ù ÙÙÙØ² 8Ø§ÙØµØ¨Ø­ Ù Ø...   \n",
       "265700           tukata  @pammanista à¸¨à¸²à¸¥à¸à¸£à¸°à¸ à¸¹à¸¡à¸´ na ...   \n",
       "...                 ...                                                ...   \n",
       "1583033         im_nlfb  @traquannet Chá»? tÃ­ nhÃ©, mÃ¬nh cÃ i tweetde...   \n",
       "1583052          5ummer  @manubkk @bkkdude Tks for sharing ka.  But if ...   \n",
       "1586631  LaMiaVitaBella  @RawkerChick Currently obsessed with...WATERME...   \n",
       "1587593         kuturak  Ð?Ð°Ñ?ÑÑÐ¾ÐµÐ½Ð¸ÐµÑÐ¾ Ð¼Ð¸ Ð´Ð½ÐµÑ? Ðµ Ð² Ð...   \n",
       "1595705        gchandra  @ravidreams orutharuku onnu pudikathunu therin...   \n",
       "\n",
       "         text_len  \n",
       "245571        166  \n",
       "248243        156  \n",
       "258460        181  \n",
       "258511        154  \n",
       "265700        151  \n",
       "...           ...  \n",
       "1583033       170  \n",
       "1583052       151  \n",
       "1586631       151  \n",
       "1587593       167  \n",
       "1595705       186  \n",
       "\n",
       "[139 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 150\n",
    "mask1 = train_df['text_len'] > max_len\n",
    "print(\"Tweets longer than {0} characters\".format(max_len))\n",
    "train_df.loc[mask1, ['user', 'text', 'text_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f75d1797410>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[mask1, 'text_len'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,599,306 records remaining in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df[~mask1].drop('text_len', axis=1)\n",
    "print(\"{0:,} records remaining in the DataFrame.\".format(len(train_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse hashtags from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashtags have been extracted into a new column 'hashtags' of the DataFrame!Took 2.77 seconds (0.05 minutes)\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "train_df['hashtags'] = train_df['text'].apply(lambda text: \" \".join(re.findall(r'#\\w+', text)))\n",
    "elapsed = time() - t\n",
    "print(\"Hashtags have been extracted into a new column 'hashtags' of the DataFrame!\"\n",
    "      \"Took {0:,.2f} seconds ({1:,.2f} minutes)\".format(elapsed, elapsed / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse user handles from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User @ handles have been extracted into a new column 'handles' of the DataFrame!Took 3.35 seconds (0.06 minutes)\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "train_df['handles'] = train_df['text'].apply(lambda text: \" \".join(re.findall(r'@\\w+', text)))\n",
    "elapsed = time() - t\n",
    "print(\"User @ handles have been extracted into a new column 'handles' of the DataFrame!\"\n",
    "      \"Took {0:,.2f} seconds ({1:,.2f} minutes)\".format(elapsed, elapsed / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply text preprocessor\n",
    "Preprocessor defined in `nlp_utils` does the following:\n",
    "* Converts all words to lower case \n",
    "* Removes all non-word characters\n",
    "* Moves emoticons to the end of the string, remove the \"nose\" symbol '-'\n",
    "* Removes all non-English unicode characters (not from the ASCII character set)\n",
    "* Strips leading and trailing whiteplace, replaces multiple spaces with a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def preprocessor(text):\n",
    "    \"\"\"\n",
    "    text preprocessor\n",
    "    :param text: an input string\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # remove everything between '<' and '>', can be used to remove HTML tags\n",
    "    # text = re.sub('<[^>]*>', '', text)\n",
    "    # temporarily store all emoticons\n",
    "    emoticons = re.findall('[:;=](?:-)?[)(D|\\(/)\\(\\)]', text)\n",
    "    # lower case, remove all non-word characters, add emoticons to the end of the string, remove the \"nose\" '-'\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', ''))\n",
    "    # remove non-English unicode characters (not from the ASCII character set)\n",
    "    text = re.sub('[^\\x00-\\x7F]', '', text)\n",
    "    # strip leading and trailing whitespaces, replace multiple spaces with a single\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO does not detect ':\\', ':/', leaves 'p' and 'd' for ':D' and ':P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is p a test :) :| :( :)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(\"     :\\ This :)    is :| *%^        :( <?> ä½ä¹ :-P a test :-)!     \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6483       Ï '??k  **pouty face** Shitty day out in Bost...\n",
       "175326     Oh joy its gong to be a long weekebd... Yipee ...\n",
       "240454     faceyourmanga.com áá±áá¬áá¹á¸áá°á...\n",
       "240464     @Buou å¦å èå å¤±è¯¯ä¸è¶ åæ?¥å?¶æ²¡æ...\n",
       "240578     nÎ±o curti Î± musicÎ± novÎ± dÎ± @fresnorock nÎ±o \n",
       "                                 ...                        \n",
       "1599682    @perequintana ara sÃ­ que ets tot un \"pirata\" ...\n",
       "1599911    Oh my god. Cookie dough frijj. I just spaffed ...\n",
       "1599933    Lmao @seizuresalad that was cute and awesome  ...\n",
       "1599980    @myheartandmind jo jen by nemuselo zrovna tÃ© ...\n",
       "1599996    TheWDB.com - Very cool to hear old Walt interv...\n",
       "Name: text, Length: 9795, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1 = train_df['text'].str.contains('[^\\x00-\\x7F]')\n",
    "train_df.loc[mask1, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessor applied to corpus, took 32.84 seconds (0.55 minutes)\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "train_df['text'] = train_df['text'].apply(preprocessor)\n",
    "elapsed = time() - t\n",
    "print(\"Text preprocessor applied to corpus, took {0:,.2f} seconds ({1:,.2f} minutes)\"\n",
    "      .format(elapsed, elapsed / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: text, dtype: object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1 = train_df['text'].str.contains('[^\\x00-\\x7F]')\n",
    "train_df.loc[mask1, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: text, dtype: object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1 = train_df['text'].str.contains('  ')\n",
    "train_df.loc[mask1, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Save results to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to file\n",
      "../../data/sentiment140/sentiment140_train_cleaned.csv\n",
      "took 14.77 seconds (0.25 minutes)\n"
     ]
    }
   ],
   "source": [
    "save_path = data_dir + 'sentiment140_train_cleaned.csv'\n",
    "t = time()\n",
    "train_df.to_csv(save_path, index=False)\n",
    "elapsed = time() - t\n",
    "print(\"DataFrame saved to file\\n{0}\\ntook {1:,.2f} seconds ({2:,.2f} minutes)\"\n",
    "      .format(save_path, elapsed, elapsed / 60))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
