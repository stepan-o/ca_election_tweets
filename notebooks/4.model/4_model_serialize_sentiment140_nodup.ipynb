{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 Canadian Election tweets\n",
    "# OSEMN Step 4: Model\n",
    "# Sentiment analysis of Sentiment 140 dataset\n",
    "# Serialize trained model\n",
    "\n",
    "This notebook describes part of Step 4: Explore of OSEMN methodology. It covers serialization of a classifier trained on Sentiment 140 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " 'src',\n",
       " 'notebooks',\n",
       " 'presentations',\n",
       " 'methodology',\n",
       " 'README.md',\n",
       " 'data']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testdata.manual.2009.06.14.csv',\n",
       " 'training.1600000.processed.noemoticon.csv',\n",
       " 'sentiment140_train_nodup.csv',\n",
       " 'sentiment140_train_cleaned.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../../data/sentiment140/'\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cleaned Sentiment 140 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- DataFrame loaded\n",
      "in 4.67 seconds\n",
      "with 1,309,540 rows\n",
      "and 8 columns\n",
      "-- Column names:\n",
      " Index(['sentiment', 'ids', 'date', 'query', 'user', 'text', 'hashtags',\n",
      "       'handles'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "df = pd.read_csv(data_dir + 'sentiment140_train_nodup.csv')\n",
    "elapsed = time() - t\n",
    "print(\"----- DataFrame loaded\"\n",
    "      \"\\nin {0:.2f} seconds\".format(elapsed) +\n",
    "      \"\\nwith {0:,} rows\\nand {1:,} columns\"\n",
    "      .format(df.shape[0], df.shape[1]) +\n",
    "      \"\\n-- Column names:\\n\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = df['sentiment'] == 4\n",
    "df.loc[mask1, 'sentiment'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test a classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "tokenizer('runners like running and thus they run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed train-test split.\n",
      "Labels counts in y: [678182 631358]\n",
      "Labels counts in y_train: [474727 441951]\n",
      "Labels counts in y_test: [203455 189407]\n"
     ]
    }
   ],
   "source": [
    "X = df['text']\n",
    "y = df['sentiment']\n",
    "\n",
    "bow = CountVectorizer(ngram_range=(1,1), tokenizer=tokenizer)\n",
    "X_bow = bow.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.3, \n",
    "                                                    random_state=random_state, stratify=y)\n",
    "print(\"Performed train-test split.\")\n",
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit, score on test set: 0.8004464672073145. Took 19.42 seconds (0.32 minutes)\n"
     ]
    }
   ],
   "source": [
    "penalty = 'l1'\n",
    "c = 1.0\n",
    "clf = LogisticRegression(random_state=random_state, solver='liblinear', penalty=penalty, C=c)\n",
    "t = time()\n",
    "clf.fit(X_train, y_train)\n",
    "elapsed = time() - t\n",
    "print(\"Model fit, score on test set: {0}. Took {1:,.2f} seconds ({2:,.2f} minutes)\"\n",
    "      .format(clf.score(X_test, y_test), elapsed, elapsed / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize the fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit, took 24.67 seconds (0.41 minutes)\n",
      "\n",
      "Model saved to:\n",
      "  results/models/lr_l1_1.0_bow_1gram_tok.pkl\n",
      "Vectorizer vocabulary saved to:\n",
      "  results/models/bow_1gram_tok_vocabulary.pkl\n"
     ]
    }
   ],
   "source": [
    "vect_name = 'bow_1gram_tok'\n",
    "model_name = 'lr_{0}_{1}_{2}'.format(penalty, c, vect_name)\n",
    "\n",
    "X = df['text']\n",
    "y = df['sentiment']\n",
    "\n",
    "bow = CountVectorizer(ngram_range=(1,1), tokenizer=tokenizer)\n",
    "X_bow = bow.fit_transform(X)\n",
    "\n",
    "clf = LogisticRegression(random_state=random_state, solver='liblinear', penalty=penalty, C=c)\n",
    "t = time()\n",
    "clf.fit(X_bow, y)\n",
    "elapsed = time() - t\n",
    "print(\"Model fit, took {0:,.2f} seconds ({1:,.2f} minutes)\".format(elapsed, elapsed / 60))\n",
    "\n",
    "dest = os.path.join('results', 'models')\n",
    "clf_save_path = os.path.join(dest, '{0}.pkl'.format(model_name))\n",
    "voc_save_path = os.path.join(dest, '{0}_vocabulary.pkl'.format(vect_name))\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "\n",
    "pickle.dump(clf, open(clf_save_path, 'wb'), protocol=4)\n",
    "print(\"\\nModel saved to:\\n  {0}\".format(clf_save_path))\n",
    "\n",
    "pickle.dump(bow.vocabulary_, open(voc_save_path, 'wb'), protocol=4)\n",
    "print(\"Vectorizer vocabulary saved to:\\n  {0}\".format(voc_save_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
